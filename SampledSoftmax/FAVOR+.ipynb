{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Copy of [HX] FINAL Sep22_FAVOR [Trainable Class Emb] [tau=None tauhc=1].ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"Pe3n1fWudx2k"},"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  \n","  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n","  print('and then re-execute this cell.')\n","else:\n","  print(gpu_info)\n","\n","\n","from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n","  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n","  print('re-execute this cell.')\n","  \n","else:\n","  print('You are using a high-RAM runtime!')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FBXFtMqqJHqP"},"source":["\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","\n","import torch\n","os.chdir('/content/drive/MyDrive/SampledSoftmaxSelf/LSTM')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CBueFVsGejQR"},"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wXgMsBADDIS_"},"source":["device"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E8TmzHkMUmI0"},"source":["## RNN Model"]},{"cell_type":"code","metadata":{"id":"AzyDFd2zUk4d"},"source":["\n","import torch.nn as nn\n","\n","\n","class RNNModel2(nn.Module):\n","\n","    def __init__(self, ntoken, ninp, nhid, nout, nlayers, dropout=0.5):\n","        super(RNNModel2, self).__init__()\n","\n","        self.nhid = nhid\n","        self.nlayers = nlayers\n","\n","        # encoder -> dropout\n","        self.drop = nn.Dropout(dropout)\n","        self.encoder = nn.Embedding(ntoken, ninp) # Token2Embeddings\n","        \n","        # lstm\n","        self.rnn = nn.LSTM(ninp, nhid, nlayers, dropout=dropout) #(seq_len, batch_size, emb_size)\n","\n","        self.init_weights() # initialize weights in encoder\n","\n","\n","    def init_weights(self):\n","        initrange = 0.05\n","        self.encoder.weight.data.uniform_(-initrange, initrange)\n","\n","\n","    def forward(self, emb, hidden):\n","        emb = self.drop(self.encoder(emb))\n","        \n","        output, hidden = self.rnn(emb, hidden)\n","        output = self.drop(output)\n","        \n","        return output.view(output.size(0)*output.size(1), output.size(2)), hidden\n","\n","    \n","    def init_hidden(self, bsz):\n","        # LSTM h and c\n","        weight = next(self.parameters()).data\n","        return weight.new_zeros(self.nlayers, bsz, self.nhid), weight.new_zeros(self.nlayers, bsz, self.nhid)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tikwUUOqFYgO"},"source":["# LATM + Sampled Softmax"]},{"cell_type":"code","metadata":{"id":"Zi15KJheJHqP"},"source":["import argparse\n","import time\n","import math\n","import torch\n","import torch.nn as nn\n","import corpus\n","import easydict\n","import torch.nn.functional as F\n","from utils import *\n","import torch.optim as optim\n","\n","args = easydict.EasyDict({\n","  \"checkpoint\": '', \n","  \"data\": './input',\n","  \"emsize\": 512,\n","  \"nhid\": 512,\n","  \"nlayers\": 2,\n","  \"lr\": 20,\n","  \"clip\": 0.35,\n","  \"epochs\": 50,\n","  \"batch_size\": 20,\n","  \"bptt\": 35,\n","  \"dropout\": 0.5,\n","  \"save\": './output/model.pt',\n","  \"opt\": \"Adam\",\n","  \"softmax_nsampled\": 40,\n","  \"method\": 'RandomFeature',\n","  \"sub_method\": \"FAVOR\",\n","  \"rf_D\": 1024,\n","  \"normalize_phi\": True,\n","  \"tau\": None,\n","  \"tau_hc\": 1,\n","  \"dataset\": 'ptb'\n","  \n","})\n","\n","\n","\n","torch.manual_seed(1111)\n","torch.cuda.manual_seed(1111)\n","\n","\n","# Load data\n","corpus = corpus.Corpus(args.data, args.dataset)\n","\n","\n","def batchify(data, bsz):\n","    nbatch = data.size(0) // bsz\n","    data = data.narrow(0, 0, nbatch * bsz)\n","    data = data.view(bsz, -1).t().contiguous()\n","    return data\n","\n","\n","eval_batch_size = 10\n","train_data = batchify(corpus.train, args.batch_size) # size(total_len//bsz, bsz)\n","val_data = batchify(corpus.valid, eval_batch_size)\n","test_data = batchify(corpus.test, eval_batch_size)\n","\n","\n","# Build the model\n","interval = 700 # interval to report\n","ntokens = len(corpus.dictionary) # 10000\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9NWtyx9nebyU"},"source":["## RandomFeature Sampler"]},{"cell_type":"code","metadata":{"id":"VzGwNMbFecLz"},"source":["\n","class RandomFeatureSampler(object):\n","  \n","    def __init__(self, rf_D, nhid, sub_method):\n","\n","        self.D = rf_D\n","        self.sub_method = sub_method\n","        \n","        if self.sub_method == 'RFF':\n","            self.orth = torch.randn(rf_D, nhid, dtype = torch.float32).to(device)\n","        elif self.sub_method == 'FAVOR':\n","            self.orth = torch.randn(rf_D, nhid, dtype = torch.float32).to(device)\n","\n","\n","\n","    # for sampled full-softmax, rff, and favor\n","    def generate_phi(self,  orth_emb):\n","        if self.sub_method == 'RFF':\n","            phi =  np.sqrt(1/args.rf_D)* torch.hstack( (torch.cos(orth_emb), torch.sin(orth_emb)) )\n","        elif self.sub_method == 'FAVOR':\n","            phi =  np.sqrt(1/(2*args.rf_D))* torch.hstack( (torch.exp(orth_emb), torch.exp(-orth_emb)) )\n","\n","        return phi\n","\n","\n","\n","\n","    def sample(self, inputs_emb, class_emb_weight, labels, num_samples):\n","        \n","        num_datapoints = inputs_emb.shape[0]\n","        \n","        if (self.sub_method == 'RFF') or (self.sub_method == 'FAVOR'):\n","            inputs_emb = torch.Tensor(inputs_emb).to(device)\n","            class_emb_weight = torch.Tensor(class_emb_weight).to(device)\n","\n","\n","            orth_inputs_emb = torch.matmul(inputs_emb, self.orth.T)\n","            phi_h = self.generate_phi(orth_inputs_emb)\n","\n","            orth_class_emb_weight = torch.matmul(class_emb_weight, self.orth.T)\n","            phi_c = self.generate_phi(orth_class_emb_weight)\n","\n","\n","        if (self.sub_method == 'RFF') or (self.sub_method == 'FAVOR'):\n","            # first calculate un-normalized q_matrix\n","            q_matrix = torch.matmul(phi_h, phi_c.T) #/ torch.sum(torch.matmul(phi_h, phi_c.T), axis = 1).unsqueeze(1)\n","            q_matrix[q_matrix<0] = 0\n","            true_class_emb = torch.index_select(phi_c, 0, labels)\n","            true_qs = torch.sum(phi_h * true_class_emb, axis = 1) #/ torch.matmul(phi_h, torch.sum(phi_c, axis = 0))\n","            true_qs /= torch.sum(q_matrix, axis = 1) # normalized true_qs. to real probability\n","            q_matrix = (q_matrix  / torch.sum(q_matrix, axis = 1).unsqueeze(1)) #normalize q_matrix to real probability\n","       \n","\n","        sampled_ids = torch.multinomial(q_matrix, num_samples, replacement=True)#.to(device)\n","        sampled_qs = torch.gather(q_matrix, 1, sampled_ids)\n","\n","            \n","        return sampled_ids, true_qs, sampled_qs \n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4Od2g4xh4dGV"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mG3Fr04-mms4"},"source":["## Sampled Softmax"]},{"cell_type":"code","metadata":{"id":"xDXL3O64moIR"},"source":["\n","\n","class SampledSoftmax(nn.Module):\n","    def __init__(self, ntokens, nsampled, nhid):\n","        super(SampledSoftmax, self).__init__()\n","\n","        # Parameters\n","        self.ntokens = ntokens\n","        self.nsampled = nsampled\n","        self.method = args.method\n","\n","        self.sampler = RandomFeatureSampler(args.rf_D, nhid, args.sub_method)\n","            \n","        self.class_emb = (nn.Embedding(ntokens, nhid)) #.to(device) # size of [d, n] \n","        \n","        self.init_weights()\n","\n","        \n","\n","\n","    def init_weights(self):\n","        initrange = 0.12\n","        self.class_emb.weight.data.uniform_(-initrange, initrange)\n","\n","\n","    def forward(self, inputs_emb, labels):\n","\n","\n","        if args.normalize_phi == True:\n","            normalized_class_emb_weight_data = args.tau_hc * F.normalize(sampled_softmax.class_emb.weight, p=2, dim=1).cpu().detach().numpy()\n","            normalized_inputs_emb = args.tau_hc * F.normalize(inputs_emb, p=2, dim=1).cpu().detach().numpy()\n","\n","        if self.training:\n","            if args.normalize_phi == True:\n","                sample_values = self.sampler.sample(normalized_inputs_emb, normalized_class_emb_weight_data, labels, self.nsampled)\n","            return self.sampled(inputs_emb, labels, sample_values, remove_accidental_match=True)\n","\n","        else:\n","            return self.full(inputs_emb)\n","           \n","\n","\n","\n","    def sampled(self, inputs_emb, labels, sample_values, remove_accidental_match=False):\n","\n","        batch_size, d = inputs_emb.size()\n","        sample_ids, true_freq, sample_freq = sample_values\n","\n","        sample_ids = sample_ids.to(device)\n","        true_freq = true_freq.to(device)\n","        sample_freq = sample_freq.to(device)\n","\n","        # true class embedding is normalized, but true logits is scaled with args.tau\n","        true_class_emb = torch.index_select(self.class_emb.weight, 0, labels)\n","\n","        true_logits =  torch.sum(torch.mul(inputs_emb, true_class_emb), dim=1)\n","        sample_logits = torch.gather(torch.matmul(inputs_emb, self.class_emb.weight.T), 1, sample_ids)\n","\n","        # remove true labels from sample set\n","        if remove_accidental_match:\n","            sample_logits += (labels.unsqueeze(1) == sample_ids)*(-1e37)\n","\n","        # perform correction\n","        true_logits = true_logits.sub(torch.log(true_freq*self.nsampled))\n","        sample_logits = sample_logits.sub(torch.log(sample_freq*self.nsampled))\n","\n","        # return logits and new_labels\n","        logits = torch.cat((torch.unsqueeze(true_logits, dim=1), sample_logits), dim=1)\n","        new_targets = Variable(torch.zeros(batch_size).long()).to(device)\n","\n","        return logits, new_targets\n","\n","    def full(self, inputs_emb):\n","        return torch.matmul(inputs_emb, self.class_emb.weight.T) # of size [700, 10000]\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cOTUojnvH1a-"},"source":["## train & val"]},{"cell_type":"code","metadata":{"id":"jYlWbl-RFbr8"},"source":["\n","def evaluate(data_source):\n","    # Turn on evaluation mode which disables dropout.\n","    with torch.no_grad():\n","        model.eval()\n","        total_loss = 0\n","        hidden = model.init_hidden(eval_batch_size)\n","        for i in range(0, data_source.size(0) - 1, args.bptt):# iterate over every timestep\n","            data, targets = get_batch(data_source, i, args.bptt)\n","            data, targets = data.to(device), targets.to(device)\n","            \n","            hidden = repackage_hidden(hidden,  device) #####?????\n","            \n","            # run RNN model\n","            output, hidden = model(data, hidden)\n","\n","            # run decoder\n","            if args.method == 'Full':\n","                logits = decoder(output)\n","            else:\n","                logits = sampled_softmax.full(output)\n","            \n","            \n","            total_loss += len(data) * criterion(logits, targets).data\n","            \n","        return total_loss.item() / len(data_source)\n","\n","\n","\n","\n","\n","\n","def train():\n","\n","    model.train()\n","    total_loss = 0\n","    #start_time = time.time()\n","    softmax_time_total = 0\n","    hidden = model.init_hidden(args.batch_size)\n","\n","    for batch, i in enumerate(range(0, train_data.size(0) - 1, args.bptt)):\n","        data, targets = get_batch(train_data, i, args.bptt)\n","        data, targets = data.to(device), targets.to(device)\n","\n","        hidden = repackage_hidden(hidden,  device)\n","        \n","        # run RNN model\n","        output, hidden = model(data, hidden)\n","\n","        start_time = time.time() ### start time\n","\n","        if args.method == 'Full':\n","            logits = decoder(output)\n","        else:\n","            logits, new_targets = sampled_softmax(output, targets)\n","\n","        softmax_time_total += time.time() - start_time ### end time \n","\n","        optimizer.zero_grad()\n","\n","        \n","        # loss\n","        if args.method == 'Full':\n","            loss = criterion(logits, targets)\n","        else:\n","            loss = criterion(logits, new_targets)\n","            \n","\n","\n","        loss.backward()\n","\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n","\n","        optimizer.step()\n","\n","        total_loss += loss.data\n","\n","        if batch % interval == 0 and batch > 0:\n","            cur_loss = total_loss / interval\n","            \n","            print('| epoch {:3d} | {:5d}/{:5d} batches | lr {:02.4f} | ms/batch {:5.2f} | '\n","                    'loss {:5.2f} | ppl {:8.2f}'.format(\n","                epoch, batch, len(train_data) // args.bptt, args.lr,\n","                softmax_time_total * 1000 / interval, cur_loss, math.exp(cur_loss)))\n","            total_loss = 0\n","            softmax_time_total = 0\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N1zQm4tTlPJf"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Os68D4dNGjpW"},"source":["## FAVOR+ -- tau_hc = 1, rf_D = 1024, m = 40 10runs"]},{"cell_type":"code","metadata":{"id":"VPeUzXDKGjpe"},"source":["args.sub_method = 'FAVOR'\n","args.tau_hc =1\n","args.rf_D = 1024\n","args.softmax_nsampled = 40"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U9jDtD0SGjpe"},"source":["args"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"robvfdRrGjpe"},"source":["for run in range(10):\n","\n","    model = RNNModel2(ntokens, args.emsize, args.nhid, args.emsize, args.nlayers,  args.dropout).to(device)\n","\n","    # Load checkpoint\n","    if args.checkpoint != '':\n","        model = torch.load(args.checkpoint, map_location=lambda storage, loc: storage)\n","\n","    print(args)\n","\n","    sampled_softmax = SampledSoftmax(ntokens = ntokens, nsampled = args.softmax_nsampled, nhid = args.nhid).to(device)\n","    model.add_module(\"decoder\", sampled_softmax)\n","\n","    model.cuda()\n","\n","    # Loop over epochs.\n","    lr = args.lr\n","    best_val_loss = None\n","\n","    args.opt = 'Adam'\n","\n","    if args.opt == 'SGD':\n","        lr, args.lr = 20, 20\n","        optimizer = torch.optim.SGD(model.parameters(), lr=args.lr)\n","    if args.opt == 'Adam':\n","        lr, args.lr = 0.001, 0.001\n","        optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.99))\n","    if args.opt == 'Momentum':\n","        lr, args.lr = 20, 20\n","        optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.8)\n","    if args.opt == 'RMSprop':\n","        lr, args.lr = 0.001, 0.001\n","        optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, alpha=0.9)\n","    if args.opt == 'Adagrad':\n","        lr, args.lr = 20, 20\n","        optimizer = torch.optim.Adagrad(model.parameters(), args.lr, weight_decay=1e-5)\n","\n","\n","    criterion = nn.CrossEntropyLoss()\n","    print(model)\n","\n","\n","    try:\n","\n","        best_val_loss = None\n","        val_loss_list = []\n","        val_perp_list = []\n","\n","\n","        print(\"optimizer is:\", args.opt)\n","\n","        for epoch in range(1, args.epochs+1):\n","            epoch_start_time = time.time()\n","            train()\n","            val_loss = evaluate(val_data)\n","            val_loss_list.append(val_loss)\n","            val_perp_list.append(math.exp(val_loss))\n","            print('-' * 89)\n","            print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time), val_loss, math.exp(val_loss)))\n","            print('-' * 89)\n","            # Save the model if the validation loss is the best we've seen so far.\n","            if not best_val_loss or val_loss < best_val_loss:\n","                with open(args.save, 'wb') as f:\n","                    torch.save(model, f)\n","                best_val_loss = val_loss\n","            else:\n","                print(\"########### ?????? ############\")\n","                # Anneal the learning rate if no improvement has been seen in the validation dataset.\n","                if args.opt == 'SGD' or args.opt == 'Momentum':\n","                    args.lr /= 4.0\n","                    lr = args.lr\n","                    for group in optimizer.param_groups:\n","                        group['lr'] = args.lr\n","                        lr = args.lr\n","        \n","\n","    except KeyboardInterrupt:\n","        print('-' * 89)\n","        print('Exiting from training early')\n","\n","    # Load the best saved model.\n","    with open(args.save, 'rb') as f:\n","        model_saved = torch.load(f)\n","\n","    model = model_saved\n","\n","    # Run on test data.\n","    test_loss = evaluate(test_data)\n","    print('=' * 89)\n","    print('| End of training | test loss {:5.2f} | test perplexity {:8.2f}'.format( test_loss, math.exp(test_loss)))\n","    print('=' * 89)\n","\n","\n","    #with open('./output/FAVOR_tauhc='+str(args.tau_hc)+'_rf_D='+str(args.rf_D)+'_m='+str(args.softmax_nsampled)+'_50epochs_run'+str(run)+'.npy', 'wb') as f:\n","    #    np.save(f, np.array(val_loss_list))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ne66FQQAGjpe"},"source":[""],"execution_count":null,"outputs":[]}]}